{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":9357411,"sourceType":"datasetVersion","datasetId":5672942}],"dockerImageVersionId":30787,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install -q peft trl bitsandbytes accelerate transformers","metadata":{"execution":{"iopub.status.busy":"2024-11-03T15:26:12.175422Z","iopub.execute_input":"2024-11-03T15:26:12.176297Z","iopub.status.idle":"2024-11-03T15:26:24.817933Z","shell.execute_reply.started":"2024-11-03T15:26:12.176246Z","shell.execute_reply":"2024-11-03T15:26:24.816870Z"},"trusted":true},"outputs":[],"execution_count":1},{"cell_type":"code","source":"import os\nimport torch\nfrom datasets import load_dataset\nfrom transformers import (\n    AutoModelForCausalLM,\n    AutoTokenizer,\n    BitsAndBytesConfig,\n    HfArgumentParser,\n    TrainingArguments,\n    pipeline,\n    logging,\n)","metadata":{"execution":{"iopub.status.busy":"2024-11-03T15:26:24.820351Z","iopub.execute_input":"2024-11-03T15:26:24.820681Z","iopub.status.idle":"2024-11-03T15:26:35.058241Z","shell.execute_reply.started":"2024-11-03T15:26:24.820648Z","shell.execute_reply":"2024-11-03T15:26:35.057211Z"},"trusted":true},"outputs":[],"execution_count":2},{"cell_type":"code","source":"from peft import LoraConfig, PeftModel\nfrom trl import SFTTrainer\n\nimport warnings\nwarnings.filterwarnings('ignore')","metadata":{"execution":{"iopub.status.busy":"2024-11-03T15:26:35.059731Z","iopub.execute_input":"2024-11-03T15:26:35.060503Z","iopub.status.idle":"2024-11-03T15:26:36.044380Z","shell.execute_reply.started":"2024-11-03T15:26:35.060457Z","shell.execute_reply":"2024-11-03T15:26:36.043593Z"},"trusted":true},"outputs":[],"execution_count":3},{"cell_type":"code","source":"# The model that you want to train from the Hugging Face hub\nmodel_name = \"mosaicml/mpt-7b-instruct\"\n\n# Fine-tuned model name\nnew_model = \"mpt-7b-instruct-finetune\"\n\n################################################################################\n# QLoRA parameters\n################################################################################\n\n# LoRA attention dimension\nlora_r = 32\n\n# Alpha parameter for LoRA scaling\nlora_alpha = 16\n\n# Dropout probability for LoRA layers\nlora_dropout = 0.1\n\n################################################################################\n# bitsandbytes parameters\n################################################################################\n\n# Activate 4-bit precision base model loading\nuse_4bit = True\n\n# Compute dtype for 4-bit base models\nbnb_4bit_compute_dtype = \"float16\"\n\n# Quantization type (fp4 or nf4)\nbnb_4bit_quant_type = \"nf4\"\n\n# Activate nested quantization for 4-bit base models (double quantization)\nuse_nested_quant = False\n\n################################################################################\n# TrainingArguments parameters\n################################################################################\n\n# Output directory where the model predictions and checkpoints will be stored\noutput_dir = \"./results\"\n\n# Number of training epochs\nnum_train_epochs = 1\n\n# Enable fp16/bf16 training (set bf16 to True with an A100)\nfp16 = False\nbf16 = False\n\n# Batch size per GPU for training\nper_device_train_batch_size = 4\n\n# Batch size per GPU for evaluation\nper_device_eval_batch_size = 4\n\n# Number of update steps to accumulate the gradients for\ngradient_accumulation_steps = 1\n\n# Enable gradient checkpointing\ngradient_checkpointing = True\n\n# Maximum gradient normal (gradient clipping)\nmax_grad_norm = 0.3\n\n# Initial learning rate (AdamW optimizer)\nlearning_rate = 2e-4\n\n# Weight decay to apply to all layers except bias/LayerNorm weights\nweight_decay = 0.001\n\n# Optimizer to use\noptim = \"paged_adamw_32bit\"\n\n# Learning rate schedule\nlr_scheduler_type = \"cosine\"\n\n# Number of training steps (overrides num_train_epochs)\nmax_steps = -1\n\n# Ratio of steps for a linear warmup (from 0 to learning rate)\nwarmup_ratio = 0.03\n\n# Group sequences into batches with same length\n# Saves memory and speeds up training considerably\ngroup_by_length = True\n\n# Save checkpoint every X updates steps\nsave_steps = 0\n\n# Log every X updates steps\nlogging_steps = 100\n\n################################################################################\n# SFT parameters\n################################################################################\n\n# Maximum sequence length to use\nmax_seq_length = None\n\n# Pack multiple short examples in the same input sequence to increase efficiency\npacking = False\n\n# Load the entire model on the GPU 0\ndevice_map = \"auto\"","metadata":{"execution":{"iopub.status.busy":"2024-11-03T15:26:36.045721Z","iopub.execute_input":"2024-11-03T15:26:36.046414Z","iopub.status.idle":"2024-11-03T15:26:36.055884Z","shell.execute_reply.started":"2024-11-03T15:26:36.046365Z","shell.execute_reply":"2024-11-03T15:26:36.054916Z"},"trusted":true},"outputs":[],"execution_count":4},{"cell_type":"code","source":"import pandas as pd\nfrom datasets import Dataset\n\nPATH = \"/kaggle/input/miniproject/Scraped_Data.csv\"\ndf = pd.read_csv(PATH)\ndataset = Dataset.from_pandas(df)\ndataset = dataset.remove_columns(['url', 'length'])\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2024-11-03T15:26:36.058440Z","iopub.execute_input":"2024-11-03T15:26:36.058759Z","iopub.status.idle":"2024-11-03T15:26:36.847279Z","shell.execute_reply.started":"2024-11-03T15:26:36.058728Z","shell.execute_reply":"2024-11-03T15:26:36.846259Z"},"trusted":true},"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"                                                 url  \\\n0  https://www.nitt.edu/home/students/facilitiesn...   \n1  https://www.nitt.edu/home/students/facilitiesn...   \n2   https://www.nitt.edu/home/academics/departments/   \n3         https://www.nitt.edu/home/students/events/   \n4  https://www.nitt.edu/home/students/facilitiesn...   \n\n                                                text  length  \n0  Training and Placement NIT Trichy is an equal ...    4011  \n1  CENTRAL LIBRARY Library Catalog- Web OPAC | Ce...    4827  \n2  Academic Departments Architecture Fax: +91-431...    1279  \n3  Events The College calendar is interspersed wi...     669  \n4  Computer Support Group The Octagon - Main CC b...    9078  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>url</th>\n      <th>text</th>\n      <th>length</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>https://www.nitt.edu/home/students/facilitiesn...</td>\n      <td>Training and Placement NIT Trichy is an equal ...</td>\n      <td>4011</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>https://www.nitt.edu/home/students/facilitiesn...</td>\n      <td>CENTRAL LIBRARY Library Catalog- Web OPAC | Ce...</td>\n      <td>4827</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>https://www.nitt.edu/home/academics/departments/</td>\n      <td>Academic Departments Architecture Fax: +91-431...</td>\n      <td>1279</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>https://www.nitt.edu/home/students/events/</td>\n      <td>Events The College calendar is interspersed wi...</td>\n      <td>669</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>https://www.nitt.edu/home/students/facilitiesn...</td>\n      <td>Computer Support Group The Octagon - Main CC b...</td>\n      <td>9078</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":5},{"cell_type":"code","source":"dataset = Dataset.from_pandas(df)\ndataset = dataset.remove_columns(['url', 'length'])\ndataset","metadata":{"execution":{"iopub.status.busy":"2024-11-03T15:26:36.848625Z","iopub.execute_input":"2024-11-03T15:26:36.849068Z","iopub.status.idle":"2024-11-03T15:26:37.097372Z","shell.execute_reply.started":"2024-11-03T15:26:36.849021Z","shell.execute_reply":"2024-11-03T15:26:37.096460Z"},"trusted":true},"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"Dataset({\n    features: ['text'],\n    num_rows: 8895\n})"},"metadata":{}}],"execution_count":6},{"cell_type":"code","source":"# Load tokenizer and model with QLoRA configuration\ncompute_dtype = getattr(torch, bnb_4bit_compute_dtype)\n\nbnb_config = BitsAndBytesConfig(\n    load_in_4bit=use_4bit,\n    bnb_4bit_quant_type=bnb_4bit_quant_type,\n    bnb_4bit_compute_dtype=compute_dtype,\n    bnb_4bit_use_double_quant=use_nested_quant,\n)","metadata":{"execution":{"iopub.status.busy":"2024-11-03T15:26:37.098375Z","iopub.execute_input":"2024-11-03T15:26:37.098674Z","iopub.status.idle":"2024-11-03T15:26:37.104682Z","shell.execute_reply.started":"2024-11-03T15:26:37.098643Z","shell.execute_reply":"2024-11-03T15:26:37.103756Z"},"trusted":true},"outputs":[],"execution_count":7},{"cell_type":"code","source":"# Check GPU compatibility with bfloat16\nif compute_dtype == torch.float16 and use_4bit:\n    major, _ = torch.cuda.get_device_capability()\n    if major >= 8:\n        print(\"=\" * 80)\n        print(\"Your GPU supports bfloat16: accelerate training with bf16=True\")\n        print(\"=\" * 80)","metadata":{"execution":{"iopub.status.busy":"2024-11-03T15:26:37.105819Z","iopub.execute_input":"2024-11-03T15:26:37.106293Z","iopub.status.idle":"2024-11-03T15:26:37.201353Z","shell.execute_reply.started":"2024-11-03T15:26:37.106244Z","shell.execute_reply":"2024-11-03T15:26:37.200553Z"},"trusted":true},"outputs":[],"execution_count":8},{"cell_type":"code","source":"# Load base model\nmodel = AutoModelForCausalLM.from_pretrained(\n    model_name,\n    quantization_config=bnb_config,\n    device_map=device_map\n)\nmodel.config.use_cache = False\nmodel.config.pretraining_tp = 1","metadata":{"execution":{"iopub.status.busy":"2024-11-03T15:26:37.202391Z","iopub.execute_input":"2024-11-03T15:26:37.202689Z","iopub.status.idle":"2024-11-03T15:26:51.537610Z","shell.execute_reply.started":"2024-11-03T15:26:37.202658Z","shell.execute_reply":"2024-11-03T15:26:51.536615Z"},"trusted":true},"outputs":[{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"73235f3645d147028d0012074f541aee"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors.index.json:   0%|          | 0.00/16.8k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c7c5e59bc3d44092962e50122d695ad5"}},"metadata":{}}],"execution_count":9},{"cell_type":"code","source":"# Load LLaMA tokenizer\ntokenizer = AutoTokenizer.from_pretrained(model_name,\n                                          trust_remote_code=True)\ntokenizer.pad_token = tokenizer.eos_token\ntokenizer.padding_side = \"right\" # Fix weird overflow issue with fp16 training","metadata":{"execution":{"iopub.status.busy":"2024-11-03T15:26:51.538780Z","iopub.execute_input":"2024-11-03T15:26:51.539132Z","iopub.status.idle":"2024-11-03T15:26:51.726961Z","shell.execute_reply.started":"2024-11-03T15:26:51.539097Z","shell.execute_reply":"2024-11-03T15:26:51.726186Z"},"trusted":true},"outputs":[],"execution_count":10},{"cell_type":"code","source":"# Load LoRA configuration\npeft_config = LoraConfig(\n    lora_alpha=lora_alpha,\n    lora_dropout=lora_dropout,\n    r=lora_r,\n    bias=\"none\",\n    task_type=\"MASKED_LM\",\n)","metadata":{"execution":{"iopub.status.busy":"2024-11-03T15:26:51.728205Z","iopub.execute_input":"2024-11-03T15:26:51.728957Z","iopub.status.idle":"2024-11-03T15:26:51.733668Z","shell.execute_reply.started":"2024-11-03T15:26:51.728911Z","shell.execute_reply":"2024-11-03T15:26:51.732727Z"},"trusted":true},"outputs":[],"execution_count":11},{"cell_type":"code","source":"training_args = TrainingArguments(\n    output_dir=output_dir,\n    num_train_epochs=num_train_epochs,\n    per_device_train_batch_size=per_device_train_batch_size,\n    per_device_eval_batch_size=per_device_eval_batch_size,\n    gradient_accumulation_steps=gradient_accumulation_steps,\n    gradient_checkpointing=gradient_checkpointing,\n    max_grad_norm=max_grad_norm,\n    learning_rate=learning_rate,\n    weight_decay=weight_decay,\n    optim=optim,\n    lr_scheduler_type=lr_scheduler_type,\n    max_steps=max_steps,\n    warmup_ratio=warmup_ratio,\n    group_by_length=group_by_length,\n    save_steps=save_steps,\n    logging_steps=logging_steps,\n    fp16=fp16,\n    bf16=bf16,\n)","metadata":{"execution":{"iopub.status.busy":"2024-11-03T15:26:51.734885Z","iopub.execute_input":"2024-11-03T15:26:51.735249Z","iopub.status.idle":"2024-11-03T15:26:51.775853Z","shell.execute_reply.started":"2024-11-03T15:26:51.735208Z","shell.execute_reply":"2024-11-03T15:26:51.775070Z"},"trusted":true},"outputs":[],"execution_count":12},{"cell_type":"code","source":"# Set supervised fine-tuning parameters\ntrainer = SFTTrainer(\n    model=model,\n    train_dataset=dataset,\n    peft_config=peft_config,\n    dataset_text_field=\"text\",\n    max_seq_length=max_seq_length,\n    tokenizer=tokenizer,\n    args=training_args,\n    packing=packing,\n)","metadata":{"execution":{"iopub.status.busy":"2024-11-03T15:26:51.777081Z","iopub.execute_input":"2024-11-03T15:26:51.777666Z","iopub.status.idle":"2024-11-03T15:27:05.139572Z","shell.execute_reply.started":"2024-11-03T15:26:51.777621Z","shell.execute_reply":"2024-11-03T15:27:05.138785Z"},"trusted":true},"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/8895 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"42e8a2fa38f94094b542f069b564f9c0"}},"metadata":{}}],"execution_count":13},{"cell_type":"code","source":"def print_number_of_trainable_model_parameters(model):\n    trainable_model_params = 0\n    all_model_params = 0\n    for _, param in model.named_parameters():\n        all_model_params += param.numel()\n        if param.requires_grad:\n            trainable_model_params += param.numel()\n    return f\"trainable model parameters: {trainable_model_params}\\n\\\n    all model parameters: {all_model_params}\\n\\\n    percentage of trainable model parameters: {100 * trainable_model_params / all_model_params:.2f}%\"\n\nprint(print_number_of_trainable_model_parameters(model))","metadata":{"execution":{"iopub.status.busy":"2024-11-03T15:27:09.992056Z","iopub.execute_input":"2024-11-03T15:27:09.992857Z","iopub.status.idle":"2024-11-03T15:27:10.002812Z","shell.execute_reply.started":"2024-11-03T15:27:09.992793Z","shell.execute_reply":"2024-11-03T15:27:10.001857Z"},"trusted":true},"outputs":[{"name":"stdout","text":"trainable model parameters: 16777216\n    all model parameters: 3444838400\n    percentage of trainable model parameters: 0.49%\n","output_type":"stream"}],"execution_count":14},{"cell_type":"code","source":"trainer.train()","metadata":{"execution":{"iopub.status.busy":"2024-11-03T15:27:10.229789Z","iopub.execute_input":"2024-11-03T15:27:10.230107Z","iopub.status.idle":"2024-11-03T17:34:45.073347Z","shell.execute_reply.started":"2024-11-03T15:27:10.230075Z","shell.execute_reply":"2024-11-03T17:34:45.071845Z"},"trusted":true},"outputs":[{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend. Please refer to https://wandb.me/wandb-core for more information.\n\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"  ········································\n"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.011113519011111192, max=1.0…","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6cb81203269d448ca9f0177c2594c93a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.18.3"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20241103_153020-bu2zxd9g</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/onlyforkoding/huggingface/runs/bu2zxd9g' target=\"_blank\">./results</a></strong> to <a href='https://wandb.ai/onlyforkoding/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/onlyforkoding/huggingface' target=\"_blank\">https://wandb.ai/onlyforkoding/huggingface</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/onlyforkoding/huggingface/runs/bu2zxd9g' target=\"_blank\">https://wandb.ai/onlyforkoding/huggingface/runs/bu2zxd9g</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='354' max='2224' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [ 354/2224 2:03:00 < 10:53:27, 0.05 it/s, Epoch 0.16/1]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>100</td>\n      <td>2.553200</td>\n    </tr>\n    <tr>\n      <td>200</td>\n      <td>2.391500</td>\n    </tr>\n    <tr>\n      <td>300</td>\n      <td>2.296900</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn[15], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/trainer.py:2122\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   2120\u001b[0m         hf_hub_utils\u001b[38;5;241m.\u001b[39menable_progress_bars()\n\u001b[1;32m   2121\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 2122\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2123\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2124\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2125\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2126\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2127\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/trainer.py:2474\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   2471\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallback_handler\u001b[38;5;241m.\u001b[39mon_step_begin(args, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol)\n\u001b[1;32m   2473\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator\u001b[38;5;241m.\u001b[39maccumulate(model):\n\u001b[0;32m-> 2474\u001b[0m     tr_loss_step \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_items_in_batch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2476\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m   2477\u001b[0m     args\u001b[38;5;241m.\u001b[39mlogging_nan_inf_filter\n\u001b[1;32m   2478\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torch_xla_available()\n\u001b[1;32m   2479\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m (torch\u001b[38;5;241m.\u001b[39misnan(tr_loss_step) \u001b[38;5;129;01mor\u001b[39;00m torch\u001b[38;5;241m.\u001b[39misinf(tr_loss_step))\n\u001b[1;32m   2480\u001b[0m ):\n\u001b[1;32m   2481\u001b[0m     \u001b[38;5;66;03m# if loss is nan or inf simply add the average of previous logged losses\u001b[39;00m\n\u001b[1;32m   2482\u001b[0m     tr_loss \u001b[38;5;241m=\u001b[39m tr_loss \u001b[38;5;241m+\u001b[39m tr_loss \u001b[38;5;241m/\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mglobal_step \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_globalstep_last_logged)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/trainer.py:3606\u001b[0m, in \u001b[0;36mTrainer.training_step\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m   3604\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   3605\u001b[0m     loss \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mgradient_accumulation_steps\n\u001b[0;32m-> 3606\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maccelerator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mloss\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3608\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m loss\u001b[38;5;241m.\u001b[39mdetach() \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mgradient_accumulation_steps\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/accelerate/accelerator.py:2196\u001b[0m, in \u001b[0;36mAccelerator.backward\u001b[0;34m(self, loss, **kwargs)\u001b[0m\n\u001b[1;32m   2194\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlomo_backward(loss, learning_rate)\n\u001b[1;32m   2195\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 2196\u001b[0m     \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/_tensor.py:521\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    511\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    512\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    513\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    514\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    519\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    520\u001b[0m     )\n\u001b[0;32m--> 521\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    522\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    523\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/autograd/__init__.py:289\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    284\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    286\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    287\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    288\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 289\u001b[0m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    290\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    291\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    292\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    293\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    294\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    295\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    296\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    297\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/autograd/graph.py:768\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    766\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[1;32m    767\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 768\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    769\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    770\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[1;32m    771\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    772\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}],"execution_count":15},{"cell_type":"code","source":"Abhishek","metadata":{"execution":{"iopub.status.busy":"2024-11-03T17:34:45.075502Z","iopub.status.idle":"2024-11-03T17:34:45.075883Z","shell.execute_reply.started":"2024-11-03T17:34:45.075688Z","shell.execute_reply":"2024-11-03T17:34:45.075707Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{},"outputs":[],"execution_count":null}]}